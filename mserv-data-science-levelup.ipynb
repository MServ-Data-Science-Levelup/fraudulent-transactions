{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008702,"end_time":"2024-10-14T20:12:06.523856","exception":false,"start_time":"2024-10-14T20:12:06.515154","status":"completed"},"tags":[]},"source":["# Team members\n","- Bryce Grahn\n","- Michael Rolle\n","- Werner de jager\n","- Abdul Gany Osman\n","- Lavania Naidoo"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.007727,"end_time":"2024-10-14T20:12:06.539717","exception":false,"start_time":"2024-10-14T20:12:06.531990","status":"completed"},"tags":[]},"source":["# Introduction\n","The aim of this notebook is undertaking a machine learning investigation on the...."]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.007732,"end_time":"2024-10-14T20:12:06.555424","exception":false,"start_time":"2024-10-14T20:12:06.547692","status":"completed"},"tags":[]},"source":["# 1. Imports and installations"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:26:26.021982Z","iopub.status.busy":"2024-10-20T08:26:26.020598Z","iopub.status.idle":"2024-10-20T08:27:00.607847Z","shell.execute_reply":"2024-10-20T08:27:00.606111Z","shell.execute_reply.started":"2024-10-20T08:26:26.021890Z"},"trusted":true},"outputs":[],"source":["#PIP\n","!pip install plotly\n","!pip install sweetviz"]},{"cell_type":"markdown","metadata":{},"source":["# Team members\n","- Bryce Grahn\n","- Michael Rolle\n","- Werner de jager\n","- Abdul Gany Osman\n","- Lavania Naidoo"]},{"cell_type":"markdown","metadata":{},"source":["# Introduction\n","The aim of this notebook is undertaking a machine learning investigation on the...."]},{"cell_type":"markdown","metadata":{},"source":["# 1. Imports and installations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#PIP\n","!pip install plotly\n","!pip install sweetviz"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# imports\n","import os\n","import math\n","import calendar\n","import numpy as np\n","import scipy as sp\n","import pandas as pd\n","import sympy as sym\n","import seaborn as sns\n","import sklearn as sk\n","import tensorflow as tf\n","import tensorflow_decision_forests as tfdf\n","import matplotlib.pyplot as plt\n","import sweetviz as sw\n","\n","from datetime import datetime\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import  confusion_matrix, accuracy_score, classification_report\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import PowerTransformer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn import tree\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestRegressor\n","\n","# define plt settings \n","plt.rcParams[\"font.size\"] = 20 \n","plt.rcParams[\"axes.labelsize\"] = 20 \n","plt.rcParams[\"xtick.labelsize\"] = 20 \n","plt.rcParams[\"ytick.labelsize\"] = 20 \n","plt.rcParams[\"legend.fontsize\"] = 20 \n","plt.rcParams[\"figure.figsize\"] = (20,10)\n","\n","# define seaborn settings seaborn\n","sns.set(style=\"ticks\", color_codes=True)\n","sns.set_palette(\"husl\")"]},{"cell_type":"markdown","metadata":{},"source":["## Import Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["url = '/kaggle/input/payments-hackathon-rojones/Payments Fraud DataSet/'\n","\n","customers_df = pd.read_csv(url + \"customers.csv\", index_col = 'CUSTOMER_ID')\n","terminals_df = pd.read_csv(url + \"terminals.csv\", index_col = 'TERMINAL_ID')\n","merchants_df = pd.read_csv(url + \"merchants.csv\", index_col = 'MERCHANT_ID')\n","transactions_test_df = pd.read_csv(url + \"transactions_test.csv\")\n","\n","\n","# Remove last row in the train dataset to resolve multiple type issue in IS_RECURRING_TRANSACTION column\n","transactions_train_df = pd.read_csv(url + \"transactions_train.csv\", dtype={'IS_RECURRING_TRANSACTION': str})\n","transactions_train_df = transactions_train_df[transactions_train_df['IS_RECURRING_TRANSACTION'] != 'Fals']\n","transactions_train_copy = transactions_train_df\n","transactions_train_df['IS_RECURRING_TRANSACTION'] = transactions_train_df['IS_RECURRING_TRANSACTION'].astype(bool)"]},{"cell_type":"markdown","metadata":{},"source":["## Deal with missing merchant ID"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["display(transactions_test_df[transactions_test_df['TX_ID'] == 'ddaa070acea087eae360225e92c1609cea905e43'].head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"\\nSimilar transactions in the train dataset:\")\n","print(\"----------------------\")\n","\n","train_transactions = transactions_train_df[(transactions_train_df['CARD_EXPIRY_DATE'] == '03/23') & (transactions_train_df['CARD_DATA'] == '4485********995') & (transactions_train_df['CARD_BRAND'] == 'Visa') & (transactions_test_df['CARD_COUNTRY_CODE'] == 'DE')]\n","display(train_transactions.head(100))\n","\n","print(\"\\nSimilar transactions in the test dataset:\")\n","print(\"----------------------\")\n","\n","test_transactions = transactions_test_df[(transactions_test_df['CARD_EXPIRY_DATE'] == '03/23') & (transactions_test_df['CARD_DATA'] == '4485********995') & (transactions_test_df['CARD_BRAND'] == 'Visa') & (transactions_test_df['CARD_COUNTRY_CODE'] == 'DE')]\n","display(test_transactions.head(100))"]},{"cell_type":"markdown","metadata":{},"source":["#### Replace merchant ID with most common id"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Find the most common MERCHANT_ID in the dataframe\n","most_common_merchant_id = transactions_test_df['MERCHANT_ID'].mode()[0]\n","\n","# Assign the most common MERCHANT_ID to the row where TX_ID matches\n","transactions_test_df.loc[transactions_test_df['TX_ID'] == 'ddaa070acea087eae360225e92c1609cea905e43', 'MERCHANT_ID'] = most_common_merchant_id\n","\n","display(transactions_test_df[transactions_test_df['TX_ID'] == 'ddaa070acea087eae360225e92c1609cea905e43'].head())"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Understand Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Customers dataset:\")\n","print(\"----------------------\")\n","display(customers_df.info())\n","print(\"\\nterminals dataset:\")\n","print(\"----------------------\")\n","display(terminals_df.info())\n","print(\"\\nmerchants dataset:\")\n","print(\"----------------------\")\n","display(merchants_df.info())\n","print(\"\\ntransactions_test dataset:\")\n","print(\"----------------------\")\n","display(transactions_test_df.info())\n","print(\"\\ntransactions_train dataset:\")\n","print(\"----------------------\")\n","display(transactions_train_df.info())\n","print(\"\\ninput dataset:\")\n","print(\"----------------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Customers dataset:\")\n","print(\"----------------------\")\n","display(customers_df.head())\n","print(\"\\nterminals dataset:\")\n","print(\"----------------------\")\n","display(terminals_df.head())\n","print(\"\\nmerchants dataset:\")\n","print(\"----------------------\")\n","display(merchants_df.head())\n","print(\"\\ntransactions_test dataset:\")\n","print(\"----------------------\")\n","display(transactions_test_df.head())\n","print(\"\\ntransactions_train dataset:\")\n","print(\"----------------------\")\n","display(transactions_train_df.head())"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Data Preparation\n","\n","## Merge Datasets\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_train_df = pd.merge(transactions_train_df, merchants_df, on='MERCHANT_ID') \n","merged_train_df = pd.merge(merged_train_df, customers_df, on='CUSTOMER_ID')\n","merged_train_df = pd.merge(merged_train_df, terminals_df, on='TERMINAL_ID')\n","display(merged_train_df.info())\n","\n","merged_test_df = pd.merge(transactions_test_df, merchants_df, on='MERCHANT_ID')\n","merged_test_df = pd.merge(merged_test_df, customers_df, on='CUSTOMER_ID')\n","merged_test_df = pd.merge(merged_test_df, terminals_df, on='TERMINAL_ID')\n","display(merged_test_df.info())\n","\n","# DON'T FORGET TO REMOVE THIS FOR FINAL TRAINING\n","np.random.seed(42)\n","# merged_train_df = merged_train_df.sample(frac=0.3)\n","display(merged_train_df.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Check for Column Differences Between Train and Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get the column names of both DataFrames\n","train_columns = set(merged_train_df.columns)\n","test_columns = set(merged_test_df.columns)\n","\n","# Find the columns that are in the train set but not in the test set, and vice versa\n","train_only_columns = train_columns - test_columns\n","test_only_columns = test_columns - train_columns\n","\n","# Print the columns that are different\n","print(\"Columns in train but not in test:\", train_only_columns)\n","print(\"Columns in test but not in train:\", test_only_columns)"]},{"cell_type":"markdown","metadata":{},"source":["## Handle Null Values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Count the number of null values per column\n","null_counts_train = merged_train_df.isnull().sum()\n","null_counts_test = merged_test_df.isnull().sum()\n","\n","print(f\"Number of columns with null data in training set: {len(null_counts_train[null_counts_train > 0].tolist())}\")\n","print(f\"Number of columns with null data in test set: {len(null_counts_test[null_counts_test > 0].tolist())}\")\n","\n","# Plot null counts for training set\n","plt.figure(figsize=(10, 6))\n","null_counts_train[null_counts_train > 0].plot(kind='bar')\n","plt.title('Null Counts per Column (Training)')\n","plt.xlabel('Columns')\n","plt.ylabel('Null Counts')\n","plt.show()\n","\n","# Plot null counts for test set\n","plt.figure(figsize=(10, 6))\n","null_counts_test[null_counts_test > 0].plot(kind='bar')\n","plt.title('Null Counts per Column (Test)')\n","plt.xlabel('Columns')\n","plt.ylabel('Null Counts')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calculate the percentage of null values per column\n","null_percentage_train = (merged_train_df.isnull().sum() / len(merged_train_df)) * 100\n","null_percentage_test = (merged_test_df.isnull().sum() / len(merged_test_df)) * 100\n","\n","# Filter to only show columns with null values\n","null_percentage_train_filtered = null_percentage_train[null_percentage_train > 0]\n","null_percentage_test_filtered = null_percentage_test[null_percentage_test > 0]\n","\n","print(f\"Number of columns with null data in training set: {len(null_percentage_train_filtered)}\")\n","print(f\"Number of columns with null data in test set: {len(null_percentage_test_filtered)}\")\n","\n","# Plot percentage of null values for training set\n","plt.figure(figsize=(10, 6))\n","null_percentage_train_filtered.plot(kind='bar')\n","plt.title('Percentage of Null Values per Column (Training)')\n","plt.xlabel('Columns')\n","plt.ylabel('Percentage of Null Values')\n","plt.show()\n","\n","# Plot percentage of null values for test set\n","plt.figure(figsize=(10, 6))\n","null_percentage_test_filtered.plot(kind='bar')\n","plt.title('Percentage of Null Values per Column (Test)')\n","plt.xlabel('Columns')\n","plt.ylabel('Percentage of Null Values')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Add Additional Columns\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_train_df['FAILURE'] = np.where(merged_train_df['FAILURE_CODE'].isna(), False, True)\n","merged_test_df['FAILURE'] = np.where(merged_test_df['FAILURE_CODE'].isna(), False, True)\n","merged_test_df['DISTANCE_FROM_TERMINAL'] = np.sqrt((merged_test_df.x_customer_id - merged_test_df.x_terminal_id)**2 + (merged_test_df.y_customer_id - merged_test_df.y_terminal__id)**2)['DISTANCE_FROM_TERMINAL'] = np.sqrt((merged_test_df.x_customer_id - merged_test_df.x_terminal_id)**2 + (merged_test_df.y_customer_id - merged_test_df.y_terminal__id)**2)\n","merged_train_df['DISTANCE_FROM_TERMINAL'] = np.sqrt((merged_train_df.x_customer_id - merged_train_df.x_terminal_id)**2 + (merged_train_df.y_customer_id - merged_train_df.y_terminal__id)**2)['DISTANCE_FROM_TERMINAL'] = np.sqrt((merged_train_df.x_customer_id - merged_train_df.x_terminal_id)**2 + (merged_train_df.y_customer_id - merged_train_df.y_terminal__id)**2)"]},{"cell_type":"markdown","metadata":{},"source":["## Drop Failure Columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_test_df = merged_test_df.drop(['FAILURE_CODE', 'FAILURE_REASON'], axis=1)\n","merged_train_df = merged_train_df.drop(['FAILURE_CODE', 'FAILURE_REASON'], axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Visualize Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# dataset_report = sw.analyze(merged_train_df, \"TX_AMOUNT\")\n","# dataset_report.show_notebook(layout='vertical')\n","\n","# More visualizations in section 5"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Manipulate Data\n","## Combine Data for Simultaneous Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Array of Ids for submission\n","testIds = merged_test_df['TX_ID']\n","display(testIds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Combine train and test data for simultaneous data preparation, keep the TX_FRAUD column for processing\n","data = pd.concat([merged_train_df.drop('TX_FRAUD', axis=1), merged_test_df.drop('ID_JOIN', axis=1)], keys=['train', 'test'])\n","fraud = merged_train_df['TX_FRAUD']\n","\n","display(data.shape)\n","display(data.head())"]},{"cell_type":"markdown","metadata":{},"source":["## View Stats on the Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.describe()"]},{"cell_type":"markdown","metadata":{},"source":["## Convert Dates to Datetimes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert transaction timestamp to datetime\n","data['TX_DATE'] = pd.to_datetime(data['TX_TS'])\n","data = data.drop(['TX_TS'], axis=1)\n","\n","def card_expiry_to_date(expiry_str):\n","    parts = expiry_str.split('/')\n","    month = int(parts[0])\n","    year = int(parts[1])\n","    if len(str(year)) == 2:\n","        year += 2000\n","    last_day = calendar.monthrange(year, month)[1]\n","    return datetime(year, month, last_day)\n","\n","# Apply the conversion to CARD_EXPIRY_DATE\n","data['CARD_EXPIRY_DATE'] = data['CARD_EXPIRY_DATE'].apply(card_expiry_to_date)\n","\n","# List of date columns\n","dates = ['FOUNDATION_DATE', 'ACTIVE_FROM', 'TRADING_FROM', 'CARD_EXPIRY_DATE']\n","\n","# Ensure all date columns are in datetime format\n","for col in dates:\n","    data[col] = pd.to_datetime(data[col])"]},{"cell_type":"markdown","metadata":{},"source":["## Convert Datetimes to Useful Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Extract features from the transaction date\n","def categorize_time_of_day(hour):\n","    if hour < 6:\n","        return 'Night'\n","    elif hour < 12:\n","        return 'Morning'\n","    elif hour <18:\n","        return 'Afternoon'\n","    else:\n","        return 'Evening'\n","    \n","data['transaction_year'] = data['TX_DATE'].dt.year\n","data['transaction_month_sin'] = np.sin(2 * np.pi * data['TX_DATE'].dt.month / 12)\n","data['transaction_is_on_weekend'] = data['TX_DATE'].dt.dayofweek >= 5\n","data['transaction_time_of_day'] = data['TX_DATE'].dt.hour.apply(categorize_time_of_day)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Remove timezone info (make all dates timezone-naive)\n","data['TX_DATE'] = pd.to_datetime(data['TX_DATE']).dt.tz_localize(None)\n","data['CARD_EXPIRY_DATE'] = pd.to_datetime(data['CARD_EXPIRY_DATE']).dt.tz_localize(None)\n","data['FOUNDATION_DATE'] = pd.to_datetime(data['FOUNDATION_DATE']).dt.tz_localize(None)\n","data['ACTIVE_FROM'] = pd.to_datetime(data['ACTIVE_FROM']).dt.tz_localize(None)\n","data['TRADING_FROM'] = pd.to_datetime(data['TRADING_FROM']).dt.tz_localize(None)\n","\n","# Get time between transaction and other dates\n","data['days_until_expiry'] = (data['CARD_EXPIRY_DATE'] - data['TX_DATE']).dt.days\n","data['days_until_expiry'] = data['days_until_expiry'].apply(lambda x: max(x, 0)) # Convert negative values to 0\n","\n","data['days_since_company_founded'] = (data['FOUNDATION_DATE'] - data['TX_DATE']).dt.days\n","data['days_since_company_founded'] = data['days_since_company_founded'].apply(lambda x: max(x, 0))\n","                                           \n","data['days_since_company_active'] = (data['ACTIVE_FROM'] - data['TX_DATE']).dt.days\n","data['days_since_company_active'] = data['days_since_company_active'].apply(lambda x: max(x, 0))\n","                                           \n","data['days_since_company_trading'] = (data['TRADING_FROM'] - data['TX_DATE']).dt.days\n","data['days_since_company_trading'] = data['days_since_company_trading'].apply(lambda x: max(x, 0))"]},{"cell_type":"markdown","metadata":{},"source":["## Mark Entities as Having Fraud From Training Data or Not"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Step 1: Identify fraudulent customers, merchants, and terminals based on the training data\n","fraudulent_customers = set(merged_train_df[merged_train_df['TX_FRAUD'] == 1]['CUSTOMER_ID'])\n","fraudulent_merchants = set(merged_train_df[merged_train_df['TX_FRAUD'] == 1]['MERCHANT_ID'])\n","fraudulent_terminals = set(merged_train_df[merged_train_df['TX_FRAUD'] == 1]['TERMINAL_ID'])\n","\n","# Step 2: Create new columns in both training and test data to mark fraudulent IDs\n","data['customer_is_fraudulent'] = data['CUSTOMER_ID'].isin(fraudulent_customers)\n","data['merchant_is_fraudulent'] = data['MERCHANT_ID'].isin(fraudulent_merchants)\n","data['terminal_is_fraudulent'] = data['TERMINAL_ID'].isin(fraudulent_terminals)"]},{"cell_type":"markdown","metadata":{},"source":["## Drop IDs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.drop(columns=['CUSTOMER_ID','TERMINAL_ID','MERCHANT_ID','CARD_DATA','LEGAL_NAME','TX_ID'], inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Drop Date Columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.drop(columns=['CARD_EXPIRY_DATE', 'FOUNDATION_DATE', 'ACTIVE_FROM', 'TRADING_FROM', 'TX_DATE'], inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Splitting the Dataset into Categorical and Numerical Features"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["numerical_cols = data.select_dtypes(include=['int32', 'int64', 'float64'])\n","categorical_cols = data.select_dtypes(include=['object', 'bool'])\n","print('Numerical columns:')\n","print(numerical_cols.columns)\n","print('Categorical columns:')\n","print(categorical_cols.columns)\n","print(f\"Total columns in dataframe: ${len(data.columns)}\")\n","print(f\"Total numerical and categorical columns: ${len(numerical_cols.columns) + len(categorical_cols.columns)}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Get Unique Values Per Categorical Column"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get the number of unique values in each categorical column\n","unique_values_per_column = categorical_cols.nunique()\n","\n","# Display the result\n","print(unique_values_per_column)"]},{"cell_type":"markdown","metadata":{},"source":["## Encode Categorical Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#data = pd.get_dummies(data)\n","#display(data.info())\n","le_card_brand = LabelEncoder()\n","le_transaction_type = LabelEncoder()\n","le_transaction_status = LabelEncoder()\n","le_transaction_currency = LabelEncoder()\n","le_card_country_code = LabelEncoder()\n","le_is_recurring_transaction = LabelEncoder()\n","le_acquirer_id = LabelEncoder()\n","le_cardholder_auth_method = LabelEncoder()\n","le_business_type = LabelEncoder()\n","le_tax_excempt_indicator = LabelEncoder()\n","le_outlet_type = LabelEncoder()\n","le_is_on_weekend = LabelEncoder()\n","le_time_of_day = LabelEncoder()\n","le_failure = LabelEncoder()\n","le_customer_is_fraudulent = LabelEncoder()\n","le_merchant_is_fraudulent = LabelEncoder()\n","le_terminal_is_fraudulent = LabelEncoder()\n","\n","data['CARD_BRAND'] = le_card_brand.fit_transform(data['CARD_BRAND'])\n","data['TRANSACTION_TYPE'] = le_transaction_type.fit_transform(data['TRANSACTION_TYPE'])\n","data['TRANSACTION_STATUS'] = le_transaction_status.fit_transform(data['TRANSACTION_STATUS'])\n","data['TRANSACTION_CURRENCY'] = le_transaction_currency.fit_transform(data['TRANSACTION_CURRENCY'])\n","data['CARD_COUNTRY_CODE'] = le_card_country_code.fit_transform(data['CARD_COUNTRY_CODE'])\n","data['IS_RECURRING_TRANSACTION'] = le_is_recurring_transaction.fit_transform(data['IS_RECURRING_TRANSACTION'])\n","data['ACQUIRER_ID'] = le_acquirer_id.fit_transform(data['ACQUIRER_ID'])\n","data['CARDHOLDER_AUTH_METHOD'] = le_cardholder_auth_method.fit_transform(data['CARDHOLDER_AUTH_METHOD'])\n","data['BUSINESS_TYPE'] = le_business_type.fit_transform(data['BUSINESS_TYPE'])\n","data['TAX_EXCEMPT_INDICATOR'] = le_tax_excempt_indicator.fit_transform(data['TAX_EXCEMPT_INDICATOR'])\n","data['OUTLET_TYPE'] = le_outlet_type.fit_transform(data['OUTLET_TYPE'])\n","data['transaction_is_on_weekend'] = le_is_on_weekend.fit_transform(data['transaction_is_on_weekend'])\n","data['transaction_time_of_day'] = le_time_of_day.fit_transform(data['transaction_time_of_day'])\n","data['FAILURE'] = le_failure.fit_transform(data['FAILURE'])\n","data['customer_is_fraudulent'] = le_customer_is_fraudulent.fit_transform(data['customer_is_fraudulent'])\n","data['merchant_is_fraudulent'] = le_merchant_is_fraudulent.fit_transform(data['merchant_is_fraudulent'])\n","data['terminal_is_fraudulent'] = le_terminal_is_fraudulent.fit_transform(data['terminal_is_fraudulent'])"]},{"cell_type":"markdown","metadata":{},"source":["## Normalize Skewed Features"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Step 1: Compute skewness for all numerical columns\n","skewed_feats = data[numerical_cols.columns].apply(lambda x: x.skew(skipna=True))\n","\n","# Step 2: Filter columns with skewness greater than 1 or less than -1\n","skewed_feats = skewed_feats[abs(skewed_feats) > 1.00]\n","\n","# Display features with their skewness values\n","for feat, skew_value in skewed_feats.items():\n","    print(f\"Feature: {feat}, Skewness: {skew_value}\")\n","\n","# Step 3: Apply Yeo-Johnson transformation to the skewed columns\n","yeo_johnson_transformer = PowerTransformer(method='yeo-johnson')  # Initialize transformer\n","\n","# Fit and transform the skewed columns\n","data[skewed_feats.index] = yeo_johnson_transformer.fit_transform(data[skewed_feats.index])\n","\n","# Check transformed skewness to ensure it's been reduced\n","transformed_skewness = data[skewed_feats.index].apply(lambda x: x.skew(skipna=True))\n","print(\"Transformed skewness:\")\n","print(transformed_skewness)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Scaling\n","This is done to assist the models in determining the best weights for features since their magnitudes will all be within the same range."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["scaler = StandardScaler()\n","scaled_data = scaler.fit_transform(data)\n","data = pd.DataFrame(scaled_data, index=data.index, columns=data.columns)"]},{"cell_type":"markdown","metadata":{},"source":["## Heatmap"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Calculate the absolute correlation values\n","# corr = np.abs(data[numerical_cols.columns])\n","# # print(corr)\n","\n","# # Increase the figure size\n","# plt.figure(figsize=(80, 80))  # Adjust the size according to your preference\n","\n","\n","# # Create the heatmap\n","# sns.heatmap(corr, annot=True, cmap=plt.cm.Reds, vmin=0, vmax=1)\n","# # Select upper triangular portion of heatmap\n","# upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool_))\n","\n","# # Show the plot\n","# plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Feature distribution\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%matplotlib inline\n","data[numerical_cols.columns].hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8, )"]},{"cell_type":"markdown","metadata":{},"source":["## Feature scatter plots"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# n_rows = 15\n","# n_cols = 4\n","\n","# fig, axes = plt.subplots(n_rows, n_cols, figsize=(50,50))\n","\n","# for i,f in enumerate(numerical_cols.columns):\n","#   _ = sns.regplot(data=data.loc['train'], \n","#                   x=f, \n","#                   y=fraud.values,\n","#                   color=\"#00b159\",\n","#                   ax=axes[i//n_cols, i%n_cols])\n","\n","# fig.tight_layout(pad=1.5)"]},{"cell_type":"markdown","metadata":{},"source":["## View Correlation of Features to Fraud"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["corr = abs(data.loc['train'].corrwith(fraud)).sort_values(ascending=False)\n","display(corr)"]},{"cell_type":"markdown","metadata":{},"source":["## Feature Selection\n","A random forest regressor machine learning model is used to determine the best features."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rf = RandomForestRegressor()\n","rf.fit(data.loc['train'], fraud)\n","importances = rf.feature_importances_\n","feature_importances = pd.DataFrame({'Feature': data.loc['train'].columns, 'Importance': importances})\n","sorted_features = feature_importances.sort_values(by='Importance', ascending=False)\n","display(sorted_features)\n","\n","# We can decide how many of the top features we want to keep here\n","# keep_top = 100\n","# best_features = sorted_features['Feature'][:keep_top].tolist()\n","# data = data[best_features]\n","# display(data.head())"]},{"cell_type":"markdown","metadata":{},"source":["# 6. View Manipulated Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["display(data.shape)\n","display(data.info())\n","display(data.head())\n","display(data.describe())"]},{"cell_type":"markdown","metadata":{},"source":["# 7. Split Data\n","## Split out Combined Train and Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_test_final = data.loc['test']\n","x_total = data.loc['train']\n","y_total = merged_train_df[['TX_FRAUD']]\n","display(x_test_final.shape)\n","display(x_total.shape)\n","display(y_total.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Split Train Data Into Train and Test for Validation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(\n","    x_total, y_total, test_size=0.1, random_state=0)\n","print(\"x_train:\")\n","display(x_train.head())\n","print(\"x_test:\")\n","display(x_test.head())\n","print(\"y_train\")\n","display(y_train.head())\n","print(\"y_test\")\n","display(y_test.head())"]},{"cell_type":"markdown","metadata":{},"source":["# 8. Define Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dtree = DecisionTreeClassifier()\n","dtree = dtree.fit(x_train, y_train)\n","\n","tree.plot_tree(dtree)"]},{"cell_type":"markdown","metadata":{},"source":["# 9. Evaluate Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = dtree.predict(x_test)\n","print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred)) \n","print(\"Accuracy : \", accuracy_score(y_test, y_pred)*100) \n","print(\"Report : \", classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["# 10. Submission "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = dtree.predict(x_test_final)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a pandas DataFrame\n","df = pd.DataFrame({\n","    'TX_ID': testIds,\n","    'TX_FRAUD': y_pred\n","})\n","\n","# Display the DataFrame\n","print(df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Export the DataFrame to a CSV file without the index\n","df.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["display(df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["display(df.info())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:27:09.200307Z","iopub.status.busy":"2024-10-20T08:27:09.199571Z","iopub.status.idle":"2024-10-20T08:27:33.317195Z","shell.execute_reply":"2024-10-20T08:27:33.315762Z","shell.execute_reply.started":"2024-10-20T08:27:09.200232Z"},"papermill":{"duration":117.96093,"end_time":"2024-10-14T20:14:04.524224","exception":false,"start_time":"2024-10-14T20:12:06.563294","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","# imports\n","import os\n","import math\n","import calendar\n","import numpy as np\n","import scipy as sp\n","import pandas as pd\n","import sympy as sym\n","import seaborn as sns\n","import sklearn as sk\n","import tensorflow as tf\n","import tensorflow_decision_forests as tfdf\n","import matplotlib.pyplot as plt\n","import sweetviz as sw\n","\n","from datetime import datetime\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import  confusion_matrix, accuracy_score, classification_report\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import PowerTransformer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn import tree\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestRegressor\n","\n","# define plt settings \n","plt.rcParams[\"font.size\"] = 20 \n","plt.rcParams[\"axes.labelsize\"] = 20 \n","plt.rcParams[\"xtick.labelsize\"] = 20 \n","plt.rcParams[\"ytick.labelsize\"] = 20 \n","plt.rcParams[\"legend.fontsize\"] = 20 \n","plt.rcParams[\"figure.figsize\"] = (20,10)\n","\n","# define seaborn settings seaborn\n","sns.set(style=\"ticks\", color_codes=True)\n","sns.set_palette(\"husl\")"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.027986,"end_time":"2024-10-14T20:14:04.593525","exception":false,"start_time":"2024-10-14T20:14:04.565539","status":"completed"},"tags":[]},"source":["## Import Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:27:37.231191Z","iopub.status.busy":"2024-10-20T08:27:37.230186Z","iopub.status.idle":"2024-10-20T08:27:53.542265Z","shell.execute_reply":"2024-10-20T08:27:53.540570Z","shell.execute_reply.started":"2024-10-20T08:27:37.231127Z"},"papermill":{"duration":11.246449,"end_time":"2024-10-14T20:14:15.941938","exception":false,"start_time":"2024-10-14T20:14:04.695489","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["url = '/kaggle/input/payments-hackathon-rojones/Payments Fraud DataSet/'\n","\n","customers_df = pd.read_csv(url + \"customers.csv\", index_col = 'CUSTOMER_ID')\n","terminals_df = pd.read_csv(url + \"terminals.csv\", index_col = 'TERMINAL_ID')\n","merchants_df = pd.read_csv(url + \"merchants.csv\", index_col = 'MERCHANT_ID')\n","transactions_test_df = pd.read_csv(url + \"transactions_test.csv\", index_col = 'TX_ID')\n","\n","\n","# Remove last row in the train dataset to resolve multiple type issue in IS_RECURRING_TRANSACTION column\n","transactions_train_df = pd.read_csv(url + \"transactions_train.csv\", index_col = 'TX_ID', dtype={'IS_RECURRING_TRANSACTION': str})\n","transactions_train_df = transactions_train_df[transactions_train_df['IS_RECURRING_TRANSACTION'] != 'Fals']\n","transactions_train_copy = transactions_train_df\n","transactions_train_df['IS_RECURRING_TRANSACTION'] = transactions_train_df['IS_RECURRING_TRANSACTION'].astype(bool)"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Understand Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:28:07.550783Z","iopub.status.busy":"2024-10-20T08:28:07.550189Z","iopub.status.idle":"2024-10-20T08:28:09.154798Z","shell.execute_reply":"2024-10-20T08:28:09.153308Z","shell.execute_reply.started":"2024-10-20T08:28:07.550729Z"},"trusted":true},"outputs":[],"source":["print(\"Customers dataset:\")\n","print(\"----------------------\")\n","display(customers_df.info())\n","print(\"\\nterminals dataset:\")\n","print(\"----------------------\")\n","display(terminals_df.info())\n","print(\"\\nmerchants dataset:\")\n","print(\"----------------------\")\n","display(merchants_df.info())\n","print(\"\\ntransactions_test dataset:\")\n","print(\"----------------------\")\n","display(transactions_test_df.info())\n","print(\"\\ntransactions_train dataset:\")\n","print(\"----------------------\")\n","display(transactions_train_df.info())\n","print(\"\\ninput dataset:\")\n","print(\"----------------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:28:12.507127Z","iopub.status.busy":"2024-10-20T08:28:12.506601Z","iopub.status.idle":"2024-10-20T08:28:12.615522Z","shell.execute_reply":"2024-10-20T08:28:12.613935Z","shell.execute_reply.started":"2024-10-20T08:28:12.507083Z"},"trusted":true},"outputs":[],"source":["print(\"Customers dataset:\")\n","print(\"----------------------\")\n","display(customers_df.head())\n","print(\"\\nterminals dataset:\")\n","print(\"----------------------\")\n","display(terminals_df.head())\n","print(\"\\nmerchants dataset:\")\n","print(\"----------------------\")\n","display(merchants_df.head())\n","print(\"\\ntransactions_test dataset:\")\n","print(\"----------------------\")\n","display(transactions_test_df.head())\n","print(\"\\ntransactions_train dataset:\")\n","print(\"----------------------\")\n","display(transactions_train_df.head())"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.027946,"end_time":"2024-10-14T20:14:15.998200","exception":false,"start_time":"2024-10-14T20:14:15.970254","status":"completed"},"tags":[]},"source":["# 3. Data Preparation\n","\n","## Merge Datasets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:34:00.406185Z","iopub.status.busy":"2024-10-20T08:34:00.404779Z","iopub.status.idle":"2024-10-20T08:34:08.398856Z","shell.execute_reply":"2024-10-20T08:34:08.397367Z","shell.execute_reply.started":"2024-10-20T08:34:00.406101Z"},"trusted":true},"outputs":[],"source":["merged_train_df = pd.merge(transactions_train_df, merchants_df, on='MERCHANT_ID') \n","merged_train_df = pd.merge(merged_train_df, customers_df, on='CUSTOMER_ID')\n","merged_train_df = pd.merge(merged_train_df, terminals_df, on='TERMINAL_ID')\n","display(merged_train_df.info())\n","\n","merged_test_df = pd.merge(transactions_test_df, merchants_df, on='MERCHANT_ID')\n","merged_test_df = pd.merge(merged_test_df, customers_df, on='CUSTOMER_ID')\n","merged_test_df = pd.merge(merged_test_df, terminals_df, on='TERMINAL_ID')\n","display(merged_test_df.info())\n","\n","# DON'T FORGET TO REMOVE THIS FOR FINAL TRAINING\n","np.random.seed(42)\n","merged_train_df = merged_train_df.sample(frac=0.3)\n","display(merged_train_df.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Check for Column Differences Between Train and Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:34:11.478250Z","iopub.status.busy":"2024-10-20T08:34:11.477670Z","iopub.status.idle":"2024-10-20T08:34:11.487142Z","shell.execute_reply":"2024-10-20T08:34:11.485690Z","shell.execute_reply.started":"2024-10-20T08:34:11.478198Z"},"trusted":true},"outputs":[],"source":["# Get the column names of both DataFrames\n","train_columns = set(merged_train_df.columns)\n","test_columns = set(merged_test_df.columns)\n","\n","# Find the columns that are in the train set but not in the test set, and vice versa\n","train_only_columns = train_columns - test_columns\n","test_only_columns = test_columns - train_columns\n","\n","# Print the columns that are different\n","print(\"Columns in train but not in test:\", train_only_columns)\n","print(\"Columns in test but not in train:\", test_only_columns)"]},{"cell_type":"markdown","metadata":{},"source":["## Handle Null Values"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:34:13.930446Z","iopub.status.busy":"2024-10-20T08:34:13.929869Z","iopub.status.idle":"2024-10-20T08:34:15.478755Z","shell.execute_reply":"2024-10-20T08:34:15.476696Z","shell.execute_reply.started":"2024-10-20T08:34:13.930391Z"},"trusted":true},"outputs":[],"source":["# Count the number of null values per column\n","null_counts_train = merged_train_df.isnull().sum()\n","null_counts_test = merged_test_df.isnull().sum()\n","\n","print(f\"Number of columns with null data in training set: {len(null_counts_train[null_counts_train > 0].tolist())}\")\n","print(f\"Number of columns with null data in test set: {len(null_counts_test[null_counts_test > 0].tolist())}\")\n","\n","# Plot null counts for training set\n","plt.figure(figsize=(10, 6))\n","null_counts_train[null_counts_train > 0].plot(kind='bar')\n","plt.title('Null Counts per Column (Training)')\n","plt.xlabel('Columns')\n","plt.ylabel('Null Counts')\n","plt.show()\n","\n","# Plot null counts for test set\n","plt.figure(figsize=(10, 6))\n","null_counts_test[null_counts_test > 0].plot(kind='bar')\n","plt.title('Null Counts per Column (Test)')\n","plt.xlabel('Columns')\n","plt.ylabel('Null Counts')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:28:33.998081Z","iopub.status.busy":"2024-10-20T08:28:33.997511Z","iopub.status.idle":"2024-10-20T08:28:35.516801Z","shell.execute_reply":"2024-10-20T08:28:35.515277Z","shell.execute_reply.started":"2024-10-20T08:28:33.998031Z"},"trusted":true},"outputs":[],"source":["# Calculate the percentage of null values per column\n","null_percentage_train = (merged_train_df.isnull().sum() / len(merged_train_df)) * 100\n","null_percentage_test = (merged_test_df.isnull().sum() / len(merged_test_df)) * 100\n","\n","# Filter to only show columns with null values\n","null_percentage_train_filtered = null_percentage_train[null_percentage_train > 0]\n","null_percentage_test_filtered = null_percentage_test[null_percentage_test > 0]\n","\n","print(f\"Number of columns with null data in training set: {len(null_percentage_train_filtered)}\")\n","print(f\"Number of columns with null data in test set: {len(null_percentage_test_filtered)}\")\n","\n","# Plot percentage of null values for training set\n","plt.figure(figsize=(10, 6))\n","null_percentage_train_filtered.plot(kind='bar')\n","plt.title('Percentage of Null Values per Column (Training)')\n","plt.xlabel('Columns')\n","plt.ylabel('Percentage of Null Values')\n","plt.show()\n","\n","# Plot percentage of null values for test set\n","plt.figure(figsize=(10, 6))\n","null_percentage_test_filtered.plot(kind='bar')\n","plt.title('Percentage of Null Values per Column (Test)')\n","plt.xlabel('Columns')\n","plt.ylabel('Percentage of Null Values')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Add Additional Columns\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:34:19.143005Z","iopub.status.busy":"2024-10-20T08:34:19.142240Z","iopub.status.idle":"2024-10-20T08:34:19.605306Z","shell.execute_reply":"2024-10-20T08:34:19.603855Z","shell.execute_reply.started":"2024-10-20T08:34:19.142939Z"},"trusted":true},"outputs":[],"source":["merged_train_df['FAILURE'] = np.where(merged_train_df['FAILURE_CODE'].isna(), False, True)\n","merged_test_df['FAILURE'] = np.where(merged_test_df['FAILURE_CODE'].isna(), False, True)\n","merged_test_df['DISTANCE_FROM_TERMINAL'] = np.sqrt((merged_test_df.x_customer_id - merged_test_df.x_terminal_id)**2 + (merged_test_df.y_customer_id - merged_test_df.y_terminal__id)**2)['DISTANCE_FROM_TERMINAL'] = np.sqrt((merged_test_df.x_customer_id - merged_test_df.x_terminal_id)**2 + (merged_test_df.y_customer_id - merged_test_df.y_terminal__id)**2)\n","merged_train_df['DISTANCE_FROM_TERMINAL'] = np.sqrt((merged_train_df.x_customer_id - merged_train_df.x_terminal_id)**2 + (merged_train_df.y_customer_id - merged_train_df.y_terminal__id)**2)['DISTANCE_FROM_TERMINAL'] = np.sqrt((merged_train_df.x_customer_id - merged_train_df.x_terminal_id)**2 + (merged_train_df.y_customer_id - merged_train_df.y_terminal__id)**2)"]},{"cell_type":"markdown","metadata":{},"source":["## Drop Failure Columns"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:34:22.075443Z","iopub.status.busy":"2024-10-20T08:34:22.074939Z","iopub.status.idle":"2024-10-20T08:34:22.271142Z","shell.execute_reply":"2024-10-20T08:34:22.269804Z","shell.execute_reply.started":"2024-10-20T08:34:22.075399Z"},"trusted":true},"outputs":[],"source":["merged_test_df = merged_test_df.drop(['FAILURE_CODE', 'FAILURE_REASON'], axis=1)\n","merged_train_df = merged_train_df.drop(['FAILURE_CODE', 'FAILURE_REASON'], axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Visualize Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-17T21:17:20.489399Z","iopub.status.busy":"2024-10-17T21:17:20.489039Z","iopub.status.idle":"2024-10-17T21:17:20.493851Z","shell.execute_reply":"2024-10-17T21:17:20.492801Z","shell.execute_reply.started":"2024-10-17T21:17:20.489362Z"},"trusted":true},"outputs":[],"source":["# dataset_report = sw.analyze(merged_train_df, \"TX_AMOUNT\")\n","# dataset_report.show_notebook(layout='vertical')"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Manipulate Data\n","## Combine Data for Simultaneous Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:34:25.758830Z","iopub.status.busy":"2024-10-20T08:34:25.757418Z","iopub.status.idle":"2024-10-20T08:34:26.293980Z","shell.execute_reply":"2024-10-20T08:34:26.291880Z","shell.execute_reply.started":"2024-10-20T08:34:25.758768Z"},"trusted":true},"outputs":[],"source":["# Array of Ids for submission\n","testIds = merged_test_df.index\n","\n","# Combine train and test data for simultaneous data preparation, keep the TX_FRAUD column for processing\n","data = pd.concat([merged_train_df.drop('TX_FRAUD', axis=1), merged_test_df.drop('ID_JOIN', axis=1)], keys=['train', 'test'])\n","fraud = merged_train_df['TX_FRAUD']\n","\n","display(data.shape)\n","display(data.head())"]},{"cell_type":"markdown","metadata":{},"source":["## View Stats on the Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T15:00:42.080482Z","iopub.status.busy":"2024-10-19T15:00:42.079754Z","iopub.status.idle":"2024-10-19T15:00:42.640642Z","shell.execute_reply":"2024-10-19T15:00:42.639085Z","shell.execute_reply.started":"2024-10-19T15:00:42.080428Z"},"trusted":true},"outputs":[],"source":["data.describe()"]},{"cell_type":"markdown","metadata":{},"source":["## Convert Dates to Datetimes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:34:31.539314Z","iopub.status.busy":"2024-10-20T08:34:31.538754Z","iopub.status.idle":"2024-10-20T08:34:35.043770Z","shell.execute_reply":"2024-10-20T08:34:35.041957Z","shell.execute_reply.started":"2024-10-20T08:34:31.539264Z"},"trusted":true},"outputs":[],"source":["# Convert transaction timestamp to datetime\n","data['TX_DATE'] = pd.to_datetime(data['TX_TS'])\n","data = data.drop(['TX_TS'], axis=1)\n","\n","def card_expiry_to_date(expiry_str):\n","    parts = expiry_str.split('/')\n","    month = int(parts[0])\n","    year = int(parts[1])\n","    if len(str(year)) == 2:\n","        year += 2000\n","    last_day = calendar.monthrange(year, month)[1]\n","    return datetime(year, month, last_day)\n","\n","# Apply the conversion to CARD_EXPIRY_DATE\n","data['CARD_EXPIRY_DATE'] = data['CARD_EXPIRY_DATE'].apply(card_expiry_to_date)\n","\n","# List of date columns\n","dates = ['FOUNDATION_DATE', 'ACTIVE_FROM', 'TRADING_FROM', 'CARD_EXPIRY_DATE']\n","\n","# Ensure all date columns are in datetime format\n","for col in dates:\n","    data[col] = pd.to_datetime(data[col])"]},{"cell_type":"markdown","metadata":{},"source":["## Convert Datetimes to Useful Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:34:38.401563Z","iopub.status.busy":"2024-10-20T08:34:38.400983Z","iopub.status.idle":"2024-10-20T08:34:38.664594Z","shell.execute_reply":"2024-10-20T08:34:38.662609Z","shell.execute_reply.started":"2024-10-20T08:34:38.401509Z"},"trusted":true},"outputs":[],"source":["# Extract features from the transaction date\n","def categorize_time_of_day(hour):\n","    if hour < 6:\n","        return 'Night'\n","    elif hour < 12:\n","        return 'Morning'\n","    elif hour <18:\n","        return 'Afternoon'\n","    else:\n","        return 'Evening'\n","    \n","data['transaction_year'] = data['TX_DATE'].dt.year\n","data['transaction_month_sin'] = np.sin(2 * np.pi * data['TX_DATE'].dt.month / 12)\n","data['transaction_is_on_weekend'] = data['TX_DATE'].dt.dayofweek >= 5\n","data['transaction_time_of_day'] = data['TX_DATE'].dt.hour.apply(categorize_time_of_day)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:34:41.469159Z","iopub.status.busy":"2024-10-20T08:34:41.468643Z","iopub.status.idle":"2024-10-20T08:34:43.650854Z","shell.execute_reply":"2024-10-20T08:34:43.649327Z","shell.execute_reply.started":"2024-10-20T08:34:41.469114Z"},"trusted":true},"outputs":[],"source":["# Remove timezone info (make all dates timezone-naive)\n","data['TX_DATE'] = pd.to_datetime(data['TX_DATE']).dt.tz_localize(None)\n","data['CARD_EXPIRY_DATE'] = pd.to_datetime(data['CARD_EXPIRY_DATE']).dt.tz_localize(None)\n","data['FOUNDATION_DATE'] = pd.to_datetime(data['FOUNDATION_DATE']).dt.tz_localize(None)\n","data['ACTIVE_FROM'] = pd.to_datetime(data['ACTIVE_FROM']).dt.tz_localize(None)\n","data['TRADING_FROM'] = pd.to_datetime(data['TRADING_FROM']).dt.tz_localize(None)\n","\n","# Get time between transaction and other dates\n","data['days_until_expiry'] = (data['CARD_EXPIRY_DATE'] - data['TX_DATE']).dt.days\n","data['days_until_expiry'] = data['days_until_expiry'].apply(lambda x: max(x, 0)) # Convert negative values to 0\n","\n","data['days_since_company_founded'] = (data['FOUNDATION_DATE'] - data['TX_DATE']).dt.days\n","data['days_since_company_founded'] = data['days_since_company_founded'].apply(lambda x: max(x, 0))\n","                                           \n","data['days_since_company_active'] = (data['ACTIVE_FROM'] - data['TX_DATE']).dt.days\n","data['days_since_company_active'] = data['days_since_company_active'].apply(lambda x: max(x, 0))\n","                                           \n","data['days_since_company_trading'] = (data['TRADING_FROM'] - data['TX_DATE']).dt.days\n","data['days_since_company_trading'] = data['days_since_company_trading'].apply(lambda x: max(x, 0))"]},{"cell_type":"markdown","metadata":{},"source":["## Mark Entities as Having Fraud From Training Data or Not"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:34:47.239078Z","iopub.status.busy":"2024-10-20T08:34:47.238498Z","iopub.status.idle":"2024-10-20T08:34:47.491312Z","shell.execute_reply":"2024-10-20T08:34:47.489991Z","shell.execute_reply.started":"2024-10-20T08:34:47.239026Z"},"trusted":true},"outputs":[],"source":["# Step 1: Identify fraudulent customers, merchants, and terminals based on the training data\n","fraudulent_customers = set(merged_train_df[merged_train_df['TX_FRAUD'] == 1]['CUSTOMER_ID'])\n","fraudulent_merchants = set(merged_train_df[merged_train_df['TX_FRAUD'] == 1]['MERCHANT_ID'])\n","fraudulent_terminals = set(merged_train_df[merged_train_df['TX_FRAUD'] == 1]['TERMINAL_ID'])\n","\n","# Step 2: Create new columns in both training and test data to mark fraudulent IDs\n","data['customer_is_fraudulent'] = data['CUSTOMER_ID'].isin(fraudulent_customers)\n","data['merchant_is_fraudulent'] = data['MERCHANT_ID'].isin(fraudulent_merchants)\n","data['terminal_is_fraudulent'] = data['TERMINAL_ID'].isin(fraudulent_terminals)"]},{"cell_type":"markdown","metadata":{},"source":["## Drop IDs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:34:50.428677Z","iopub.status.busy":"2024-10-20T08:34:50.427393Z","iopub.status.idle":"2024-10-20T08:34:50.617847Z","shell.execute_reply":"2024-10-20T08:34:50.616471Z","shell.execute_reply.started":"2024-10-20T08:34:50.428611Z"},"trusted":true},"outputs":[],"source":["data.drop(columns=['CUSTOMER_ID','TERMINAL_ID','MERCHANT_ID','CARD_DATA','LEGAL_NAME'], inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Drop Date Columns"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:34:52.944290Z","iopub.status.busy":"2024-10-20T08:34:52.943706Z","iopub.status.idle":"2024-10-20T08:34:53.050285Z","shell.execute_reply":"2024-10-20T08:34:53.048904Z","shell.execute_reply.started":"2024-10-20T08:34:52.944238Z"},"trusted":true},"outputs":[],"source":["data.drop(columns=['CARD_EXPIRY_DATE', 'FOUNDATION_DATE', 'ACTIVE_FROM', 'TRADING_FROM', 'TX_DATE'], inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Splitting the Dataset into Categorical and Numerical Features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:34:55.537918Z","iopub.status.busy":"2024-10-20T08:34:55.537330Z","iopub.status.idle":"2024-10-20T08:34:55.839537Z","shell.execute_reply":"2024-10-20T08:34:55.838258Z","shell.execute_reply.started":"2024-10-20T08:34:55.537867Z"},"trusted":true},"outputs":[],"source":["numerical_cols = data.select_dtypes(include=['int32', 'int64', 'float64'])\n","categorical_cols = data.select_dtypes(include=['object', 'bool'])\n","print('Numerical columns:')\n","print(numerical_cols.columns)\n","print('Categorical columns:')\n","print(categorical_cols.columns)\n","print(f\"Total columns in dataframe: ${len(data.columns)}\")\n","print(f\"Total numerical and categorical columns: ${len(numerical_cols.columns) + len(categorical_cols.columns)}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Get Unique Values Per Categorical Column"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:34:59.577278Z","iopub.status.busy":"2024-10-20T08:34:59.576729Z","iopub.status.idle":"2024-10-20T08:34:59.961640Z","shell.execute_reply":"2024-10-20T08:34:59.960263Z","shell.execute_reply.started":"2024-10-20T08:34:59.577229Z"},"trusted":true},"outputs":[],"source":["# Get the number of unique values in each categorical column\n","unique_values_per_column = categorical_cols.nunique()\n","\n","# Display the result\n","print(unique_values_per_column)"]},{"cell_type":"markdown","metadata":{},"source":["## Encode Categorical Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:35:03.624739Z","iopub.status.busy":"2024-10-20T08:35:03.624136Z","iopub.status.idle":"2024-10-20T08:35:04.922072Z","shell.execute_reply":"2024-10-20T08:35:04.920575Z","shell.execute_reply.started":"2024-10-20T08:35:03.624676Z"},"trusted":true},"outputs":[],"source":["#data = pd.get_dummies(data)\n","#display(data.info())\n","le_card_brand = LabelEncoder()\n","le_transaction_type = LabelEncoder()\n","le_transaction_status = LabelEncoder()\n","le_transaction_currency = LabelEncoder()\n","le_card_country_code = LabelEncoder()\n","le_is_recurring_transaction = LabelEncoder()\n","le_acquirer_id = LabelEncoder()\n","le_cardholder_auth_method = LabelEncoder()\n","le_business_type = LabelEncoder()\n","le_tax_excempt_indicator = LabelEncoder()\n","le_outlet_type = LabelEncoder()\n","le_is_on_weekend = LabelEncoder()\n","le_time_of_day = LabelEncoder()\n","le_failure = LabelEncoder()\n","le_customer_is_fraudulent = LabelEncoder()\n","le_merchant_is_fraudulent = LabelEncoder()\n","le_terminal_is_fraudulent = LabelEncoder()\n","\n","data['CARD_BRAND'] = le_card_brand.fit_transform(data['CARD_BRAND'])\n","data['TRANSACTION_TYPE'] = le_transaction_type.fit_transform(data['TRANSACTION_TYPE'])\n","data['TRANSACTION_STATUS'] = le_transaction_status.fit_transform(data['TRANSACTION_STATUS'])\n","data['TRANSACTION_CURRENCY'] = le_transaction_currency.fit_transform(data['TRANSACTION_CURRENCY'])\n","data['CARD_COUNTRY_CODE'] = le_card_country_code.fit_transform(data['CARD_COUNTRY_CODE'])\n","data['IS_RECURRING_TRANSACTION'] = le_is_recurring_transaction.fit_transform(data['IS_RECURRING_TRANSACTION'])\n","data['ACQUIRER_ID'] = le_acquirer_id.fit_transform(data['ACQUIRER_ID'])\n","data['CARDHOLDER_AUTH_METHOD'] = le_cardholder_auth_method.fit_transform(data['CARDHOLDER_AUTH_METHOD'])\n","data['BUSINESS_TYPE'] = le_business_type.fit_transform(data['BUSINESS_TYPE'])\n","data['TAX_EXCEMPT_INDICATOR'] = le_tax_excempt_indicator.fit_transform(data['TAX_EXCEMPT_INDICATOR'])\n","data['OUTLET_TYPE'] = le_outlet_type.fit_transform(data['OUTLET_TYPE'])\n","data['transaction_is_on_weekend'] = le_is_on_weekend.fit_transform(data['transaction_is_on_weekend'])\n","data['transaction_time_of_day'] = le_time_of_day.fit_transform(data['transaction_time_of_day'])\n","data['FAILURE'] = le_failure.fit_transform(data['FAILURE'])\n","data['customer_is_fraudulent'] = le_customer_is_fraudulent.fit_transform(data['customer_is_fraudulent'])\n","data['merchant_is_fraudulent'] = le_merchant_is_fraudulent.fit_transform(data['merchant_is_fraudulent'])\n","data['terminal_is_fraudulent'] = le_terminal_is_fraudulent.fit_transform(data['terminal_is_fraudulent'])"]},{"cell_type":"markdown","metadata":{},"source":["## Normalize Skewed Features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:35:07.608083Z","iopub.status.busy":"2024-10-20T08:35:07.606974Z","iopub.status.idle":"2024-10-20T08:35:13.772178Z","shell.execute_reply":"2024-10-20T08:35:13.770785Z","shell.execute_reply.started":"2024-10-20T08:35:07.608012Z"},"trusted":true},"outputs":[],"source":["# Step 1: Compute skewness for all numerical columns\n","skewed_feats = data[numerical_cols.columns].apply(lambda x: x.skew(skipna=True))\n","\n","# Step 2: Filter columns with skewness greater than 1 or less than -1\n","skewed_feats = skewed_feats[abs(skewed_feats) > 1.00]\n","\n","# Display features with their skewness values\n","for feat, skew_value in skewed_feats.items():\n","    print(f\"Feature: {feat}, Skewness: {skew_value}\")\n","\n","# Step 3: Apply Yeo-Johnson transformation to the skewed columns\n","yeo_johnson_transformer = PowerTransformer(method='yeo-johnson')  # Initialize transformer\n","\n","# Fit and transform the skewed columns\n","data[skewed_feats.index] = yeo_johnson_transformer.fit_transform(data[skewed_feats.index])\n","\n","# Check transformed skewness to ensure it's been reduced\n","transformed_skewness = data[skewed_feats.index].apply(lambda x: x.skew(skipna=True))\n","print(\"Transformed skewness:\")\n","print(transformed_skewness)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Scaling\n","This is done to assist the models in determining the best weights for features since their magnitudes will all be within the same range."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:35:17.358315Z","iopub.status.busy":"2024-10-20T08:35:17.357745Z","iopub.status.idle":"2024-10-20T08:35:17.875894Z","shell.execute_reply":"2024-10-20T08:35:17.874256Z","shell.execute_reply.started":"2024-10-20T08:35:17.358268Z"},"trusted":true},"outputs":[],"source":["scaler = StandardScaler()\n","scaled_data = scaler.fit_transform(data)\n","data = pd.DataFrame(scaled_data, index=data.index, columns=data.columns)"]},{"cell_type":"markdown","metadata":{},"source":["## View Correlation of Features to Fraud"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:35:21.159093Z","iopub.status.busy":"2024-10-20T08:35:21.157540Z","iopub.status.idle":"2024-10-20T08:35:21.568944Z","shell.execute_reply":"2024-10-20T08:35:21.567637Z","shell.execute_reply.started":"2024-10-20T08:35:21.159011Z"},"trusted":true},"outputs":[],"source":["corr = abs(data.loc['train'].corrwith(fraud)).sort_values(ascending=False)\n","display(corr)"]},{"cell_type":"markdown","metadata":{},"source":["## Feature Selection\n","A random forest regressor machine learning model is used to determine the best features."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:35:41.033103Z","iopub.status.busy":"2024-10-20T08:35:41.032480Z","iopub.status.idle":"2024-10-20T08:38:04.949761Z","shell.execute_reply":"2024-10-20T08:38:04.948416Z","shell.execute_reply.started":"2024-10-20T08:35:41.033047Z"},"trusted":true},"outputs":[],"source":["rf = RandomForestRegressor()\n","rf.fit(data.loc['train'], fraud)\n","importances = rf.feature_importances_\n","feature_importances = pd.DataFrame({'Feature': data.loc['train'].columns, 'Importance': importances})\n","sorted_features = feature_importances.sort_values(by='Importance', ascending=False)\n","display(sorted_features)\n","\n","# We can decide how many of the top features we want to keep here\n","# keep_top = 100\n","# best_features = sorted_features['Feature'][:keep_top].tolist()\n","# data = data[best_features]\n","# display(data.head())"]},{"cell_type":"markdown","metadata":{},"source":["# 6. View Manipulated Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T08:38:57.329175Z","iopub.status.busy":"2024-10-20T08:38:57.327895Z","iopub.status.idle":"2024-10-20T08:38:58.444544Z","shell.execute_reply":"2024-10-20T08:38:58.443041Z","shell.execute_reply.started":"2024-10-20T08:38:57.329113Z"},"trusted":true},"outputs":[],"source":["display(data.shape)\n","display(data.info())\n","display(data.head())\n","display(data.describe())"]},{"cell_type":"markdown","metadata":{},"source":["# 7. Split Data\n","## Split out Combined Train and Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-17T21:17:38.300600Z","iopub.status.busy":"2024-10-17T21:17:38.299898Z","iopub.status.idle":"2024-10-17T21:17:38.324413Z","shell.execute_reply":"2024-10-17T21:17:38.323401Z","shell.execute_reply.started":"2024-10-17T21:17:38.300548Z"},"trusted":true},"outputs":[],"source":["x_test_final = data.loc['test']\n","x_total = data.loc['train']\n","y_total = merged_train_df[['TX_FRAUD']]\n","display(x_test_final.shape)\n","display(x_total.shape)\n","display(y_total.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Split Train Data Into Train and Test for Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-17T21:17:38.326220Z","iopub.status.busy":"2024-10-17T21:17:38.325910Z","iopub.status.idle":"2024-10-17T21:17:39.007440Z","shell.execute_reply":"2024-10-17T21:17:39.006418Z","shell.execute_reply.started":"2024-10-17T21:17:38.326187Z"},"trusted":true},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(\n","    x_total, y_total, test_size=0.1, random_state=0)\n","print(\"x_train:\")\n","display(x_train.head())\n","print(\"x_test:\")\n","display(x_test.head())\n","print(\"y_train\")\n","display(y_train.head())\n","print(\"y_test\")\n","display(y_test.head())"]},{"cell_type":"markdown","metadata":{},"source":["# 8. Define Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-17T21:17:39.009357Z","iopub.status.busy":"2024-10-17T21:17:39.008910Z","iopub.status.idle":"2024-10-17T21:36:51.801844Z","shell.execute_reply":"2024-10-17T21:36:51.800728Z","shell.execute_reply.started":"2024-10-17T21:17:39.009308Z"},"trusted":true},"outputs":[],"source":["dtree = DecisionTreeClassifier()\n","dtree = dtree.fit(x_train, y_train)\n","\n","tree.plot_tree(dtree)"]},{"cell_type":"markdown","metadata":{},"source":["# 9. Evaluate Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-17T21:36:51.806569Z","iopub.status.busy":"2024-10-17T21:36:51.806174Z","iopub.status.idle":"2024-10-17T21:36:52.032264Z","shell.execute_reply":"2024-10-17T21:36:52.031172Z","shell.execute_reply.started":"2024-10-17T21:36:51.806528Z"},"trusted":true},"outputs":[],"source":["y_pred = dtree.predict(x_test)\n","print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred)) \n","print(\"Accuracy : \", accuracy_score(y_test, y_pred)*100) \n","print(\"Report : \", classification_report(y_test, y_pred))"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9822803,"sourceId":58079,"sourceType":"competition"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":152.634155,"end_time":"2024-10-14T20:14:35.904156","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-10-14T20:12:03.270001","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0d24be280abe4f918d8e349f04477c3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ee0aec96dae4aab89c0fca475fb2267","IPY_MODEL_721b7a8f01f84deeb3e875b2d6fe155a","IPY_MODEL_b22285cdc3f146bdb144b4f503c2147e"],"layout":"IPY_MODEL_ef142a725a3f48c1918e318a32ba274f"}},"0ee0aec96dae4aab89c0fca475fb2267":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddd9a2f4d5d747e2a82d5f730980936d","placeholder":"​","style":"IPY_MODEL_2c2219a81ac344748784ddc0781319f0","value":"Done! Use &#x27;show&#x27; commands to display/save.   "}},"2c2219a81ac344748784ddc0781319f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"687fcb8e2fb54b68a0de2fc6d22fdb1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"721b7a8f01f84deeb3e875b2d6fe155a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bae170cef094659afa54d709641a454","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_687fcb8e2fb54b68a0de2fc6d22fdb1b","value":1}},"7bae170cef094659afa54d709641a454":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8354b7016a8340e486ed19acdf9cc4c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b22285cdc3f146bdb144b4f503c2147e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8f2036e320142ebbe34973ad0a444d8","placeholder":"​","style":"IPY_MODEL_8354b7016a8340e486ed19acdf9cc4c7","value":" [100%]   00:01 -&gt; (00:00 left)"}},"ddd9a2f4d5d747e2a82d5f730980936d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8f2036e320142ebbe34973ad0a444d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef142a725a3f48c1918e318a32ba274f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":4}
